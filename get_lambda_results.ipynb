{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leave-one-nuclide-out loop - predicting all nuclides 10 times and savind data to csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters found for each lambda are used here. Run the cells below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy scikit-learn torch optuna matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --------------------------- IMPORTS ----------------------------------\n",
    "import random, pathlib, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------- CONSTANTS --------------------------------\n",
    "CSV_PATH   = \"merged_8_july_d_lowmassremoved.csv\"          # master dataset\n",
    "BASE_OUT   = pathlib.Path(\"results_lam0\")   # parent folder for all isotopes\n",
    "DEVICE     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---- fixed hyper-parameters (λ = 0 run) ----\n",
    "LAM        = 0.0\n",
    "N_HIDDEN   = 96\n",
    "N_LAYERS   = 2\n",
    "DROPOUT    = 0.23455646448047404\n",
    "LR         = 0.001259422015017642\n",
    "\n",
    "MAX_EPOCHS = 200\n",
    "PATIENCE   = 15\n",
    "BATCH_SHUFFLE = True\n",
    "\n",
    "N_RUNS     = 10\n",
    "SEED_BASE  = 1234\n",
    "EPS        = 1e-12\n",
    "\n",
    "FEATURES = [\n",
    "    'ERG','Radius','n_rms_radius','p_rms_radius','octopole_deformation',\n",
    "    'n_chem_erg','Sn','Z','S2p_compound','gamma_deformation','ME',\n",
    "    'BEA_A_daughter','A','Radius_daughter','BEA_A','AM','Radius_compound',\n",
    "    'Pairing_daughter','BEA_compound','beta_deformation','Theory_thresh',\n",
    "    'shell_P','pairing_delta','symmetry_S','excitation_energy',\n",
    "    'Thresh_n3n','Excite_n3n','Thresh_n4n','Excite_n4n'\n",
    "]\n",
    "TARGET, SIGMA_EXP, FLUENCE, GAMMA, ISO = (\n",
    "    \"XS\",\"sigma_exp\",\"fluence\",\"gamma\",\"iso_id\"\n",
    ")\n",
    "\n",
    "# --------------------------- UTILITIES --------------------------------\n",
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# ----------------------- DATASET & SAMPLER ----------------------------\n",
    "class XSData(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, scaler: StandardScaler,\n",
    "                 fit_scaler: bool = False):\n",
    "        if fit_scaler:\n",
    "            scaler.fit(df[FEATURES])\n",
    "        self.X = torch.tensor(scaler.transform(df[FEATURES]).astype(np.float32))\n",
    "        self.y = torch.tensor(df[TARGET].to_numpy(np.float32))\n",
    "        self.fluence   = torch.tensor(df[FLUENCE].to_numpy(np.float32))\n",
    "        self.sigma_exp = torch.tensor(df[SIGMA_EXP].fillna(0).to_numpy(np.float32))\n",
    "        self.gamma     = torch.tensor(df[GAMMA].to_numpy(np.float32))\n",
    "        self.iso_code  = df[ISO].astype(\"category\").cat.codes.to_numpy()\n",
    "\n",
    "    def __len__(self): return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return {\"x\": self.X[idx], \"y\": self.y[idx],\n",
    "                \"fluence\": self.fluence[idx],\n",
    "                \"sigma_exp\": self.sigma_exp[idx],\n",
    "                \"gamma\": self.gamma[idx],\n",
    "                \"iso_code\": self.iso_code[idx]}\n",
    "\n",
    "class IsoBatchSampler(Sampler):\n",
    "    def __init__(self, iso_codes, shuffle=True):\n",
    "        self.indices = {}\n",
    "        for i, iso in enumerate(iso_codes):\n",
    "            self.indices.setdefault(int(iso), []).append(i)\n",
    "        self.keys = list(self.indices.keys())\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        keys = self.keys.copy()\n",
    "        if self.shuffle: random.shuffle(keys)\n",
    "        for k in keys:\n",
    "            yield self.indices[k]\n",
    "\n",
    "    def __len__(self): return len(self.keys)\n",
    "\n",
    "# ------------------------------ MODEL ---------------------------------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in:int, n_hidden:int, n_layers:int, p_drop:float):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for l in range(n_layers):\n",
    "            layers += [nn.Linear(n_in if l==0 else n_hidden, n_hidden),\n",
    "                       nn.ReLU(), nn.Dropout(p_drop)]\n",
    "        layers.append(nn.Linear(n_hidden, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x): return self.net(x).squeeze(1)\n",
    "\n",
    "# -------------------------- CUSTOM LOSS -------------------------------\n",
    "def iso_loss(batch, preds, lam:float):\n",
    "    mse = nn.functional.mse_loss(preds, batch[\"y\"])\n",
    "    if batch[\"gamma\"][0] == 0:     # skip σ₁g term if γ = 0\n",
    "        return mse\n",
    "    flu        = batch[\"fluence\"]\n",
    "    sigma_pred = (flu * preds).sum() / (flu.sum() + EPS)\n",
    "    sigma_true = batch[\"sigma_exp\"][0]\n",
    "    rel_err_sq = ((sigma_pred - sigma_true) / (sigma_true + EPS))**2\n",
    "    return mse + lam * rel_err_sq\n",
    "\n",
    "# ------------------------ TRAIN / VALID LOOP --------------------------\n",
    "def run_epoch(model, loader, opt, lam):\n",
    "    is_train = opt is not None\n",
    "    model.train(is_train)\n",
    "    total, n = 0.0, 0\n",
    "    for batch in loader:\n",
    "        batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                 for k,v in batch.items()}\n",
    "        preds = model(batch[\"x\"])\n",
    "        loss  = iso_loss(batch, preds, lam)\n",
    "        if is_train:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        total += loss.item() * len(preds)\n",
    "        n     += len(preds)\n",
    "    return total / n\n",
    "\n",
    "# ----------------------- PER-ISOTOPE ROUTINE --------------------------\n",
    "def process_isotope(df_all: pd.DataFrame, iso_hold: str) -> None:\n",
    "    out_dir = BASE_OUT / iso_hold\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df_test  = df_all[df_all[ISO] == iso_hold].reset_index(drop=True)\n",
    "    df_train = df_all[df_all[ISO] != iso_hold].reset_index(drop=True)\n",
    "    if df_test.empty:\n",
    "        print(f\"⚠  No rows for iso_id={iso_hold}; skipping.\")\n",
    "        return\n",
    "\n",
    "    preds_runs = []\n",
    "    for run in range(N_RUNS):\n",
    "        set_seed(SEED_BASE + run)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        ds_tr  = XSData(df_train, scaler, fit_scaler=True)\n",
    "        ds_te  = XSData(df_test,  scaler, fit_scaler=False)\n",
    "\n",
    "        dl_tr = DataLoader(ds_tr, batch_sampler=IsoBatchSampler(ds_tr.iso_code,\n",
    "                                                                shuffle=BATCH_SHUFFLE))\n",
    "        dl_te = DataLoader(ds_te, batch_sampler=IsoBatchSampler(ds_te.iso_code,\n",
    "                                                                shuffle=False))\n",
    "\n",
    "        model = MLP(len(FEATURES), N_HIDDEN, N_LAYERS, DROPOUT).to(DEVICE)\n",
    "        opt   = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "        best, patience = float(\"inf\"), 0\n",
    "        for _ in range(MAX_EPOCHS):\n",
    "            loss_tr = run_epoch(model, dl_tr, opt, LAM)\n",
    "            if loss_tr < best - 1e-6:\n",
    "                best, patience = loss_tr, 0\n",
    "            else:\n",
    "                patience += 1\n",
    "                if patience >= PATIENCE:\n",
    "                    break\n",
    "\n",
    "        # predict\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dl_te:\n",
    "                batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                         for k,v in batch.items()}\n",
    "                preds.append(model(batch[\"x\"]).cpu())\n",
    "        preds_runs.append(torch.cat(preds).numpy())\n",
    "\n",
    "    preds_arr  = np.stack(preds_runs, axis=1)\n",
    "    pred_mean  = preds_arr.mean(axis=1)\n",
    "\n",
    "    # save CSV ----------------------------------------------------------\n",
    "    df_out = pd.DataFrame({\"ERG\": df_test[\"ERG\"], \"XS_true\": df_test[\"XS\"]})\n",
    "    for r in range(N_RUNS):\n",
    "        df_out[f\"pred_run{r+1}\"] = preds_arr[:, r]\n",
    "    df_out[\"pred_mean\"] = pred_mean\n",
    "    csv_path = out_dir / f\"{iso_hold}_predictions.csv\"\n",
    "    df_out.to_csv(csv_path, index=False)\n",
    "\n",
    "    # plot --------------------------------------------------------------\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(df_out[\"ERG\"], df_out[\"XS_true\"],  lw=2, label=\"True XS\")\n",
    "    plt.plot(df_out[\"ERG\"], df_out[\"pred_mean\"], lw=2, ls=\"--\",\n",
    "             label=f\"Mean pred ({N_RUNS}×)\")\n",
    "    plt.xlabel(\"ERG\"); plt.ylabel(\"XS\")\n",
    "    plt.title(f\"{iso_hold} – true vs predicted XS\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(out_dir / f\"{iso_hold}_erg_vs_pred.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # meta --------------------------------------------------------------\n",
    "    meta = dict(lam=LAM, n_hidden=N_HIDDEN, n_layers=N_LAYERS,\n",
    "                dropout=DROPOUT, lr=LR, n_runs=N_RUNS,\n",
    "                iso_held_out=iso_hold)\n",
    "    with open(out_dir / \"run_meta.json\", \"w\") as fh:\n",
    "        json.dump(meta, fh, indent=2)\n",
    "\n",
    "    print(f\"✓ finished {iso_hold}\")\n",
    "\n",
    "# ------------------------------- MAIN ---------------------------------\n",
    "def main() -> None:\n",
    "    BASE_OUT.mkdir(parents=True, exist_ok=True)\n",
    "    df_all   = pd.read_csv(CSV_PATH)\n",
    "    iso_list = sorted(df_all[ISO].unique())\n",
    "\n",
    "    print(f\"Found {len(iso_list)} unique isotopes.\")\n",
    "    for iso in iso_list:\n",
    "        process_isotope(df_all, iso)\n",
    "\n",
    "    print(\"\\nAll isotopes done!\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------- IMPORTS ----------------------------------\n",
    "import random, pathlib, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------- CONSTANTS --------------------------------\n",
    "CSV_PATH   = \"merged_8_july_d_lowmassremoved.csv\"          # master dataset\n",
    "BASE_OUT   = pathlib.Path(\"results_lam0p1\")   # parent folder for all isotopes\n",
    "DEVICE     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---- fixed hyper-parameters (λ = 0 run) ----\n",
    "LAM        = 0.1\n",
    "N_HIDDEN   = 160\n",
    "N_LAYERS   = 3\n",
    "DROPOUT    = 0.05975904468734236\n",
    "LR         = 0.0013783694458205406\n",
    "\n",
    "MAX_EPOCHS = 200\n",
    "PATIENCE   = 15\n",
    "BATCH_SHUFFLE = True\n",
    "\n",
    "N_RUNS     = 10\n",
    "SEED_BASE  = 1234\n",
    "EPS        = 1e-12\n",
    "\n",
    "FEATURES = [\n",
    "    'ERG','Radius','n_rms_radius','p_rms_radius','octopole_deformation',\n",
    "    'n_chem_erg','Sn','Z','S2p_compound','gamma_deformation','ME',\n",
    "    'BEA_A_daughter','A','Radius_daughter','BEA_A','AM','Radius_compound',\n",
    "    'Pairing_daughter','BEA_compound','beta_deformation','Theory_thresh',\n",
    "    'shell_P','pairing_delta','symmetry_S','excitation_energy',\n",
    "    'Thresh_n3n','Excite_n3n','Thresh_n4n','Excite_n4n'\n",
    "]\n",
    "TARGET, SIGMA_EXP, FLUENCE, GAMMA, ISO = (\n",
    "    \"XS\",\"sigma_exp\",\"fluence\",\"gamma\",\"iso_id\"\n",
    ")\n",
    "\n",
    "# --------------------------- UTILITIES --------------------------------\n",
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# ----------------------- DATASET & SAMPLER ----------------------------\n",
    "class XSData(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, scaler: StandardScaler,\n",
    "                 fit_scaler: bool = False):\n",
    "        if fit_scaler:\n",
    "            scaler.fit(df[FEATURES])\n",
    "        self.X = torch.tensor(scaler.transform(df[FEATURES]).astype(np.float32))\n",
    "        self.y = torch.tensor(df[TARGET].to_numpy(np.float32))\n",
    "        self.fluence   = torch.tensor(df[FLUENCE].to_numpy(np.float32))\n",
    "        self.sigma_exp = torch.tensor(df[SIGMA_EXP].fillna(0).to_numpy(np.float32))\n",
    "        self.gamma     = torch.tensor(df[GAMMA].to_numpy(np.float32))\n",
    "        self.iso_code  = df[ISO].astype(\"category\").cat.codes.to_numpy()\n",
    "\n",
    "    def __len__(self): return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return {\"x\": self.X[idx], \"y\": self.y[idx],\n",
    "                \"fluence\": self.fluence[idx],\n",
    "                \"sigma_exp\": self.sigma_exp[idx],\n",
    "                \"gamma\": self.gamma[idx],\n",
    "                \"iso_code\": self.iso_code[idx]}\n",
    "\n",
    "class IsoBatchSampler(Sampler):\n",
    "    def __init__(self, iso_codes, shuffle=True):\n",
    "        self.indices = {}\n",
    "        for i, iso in enumerate(iso_codes):\n",
    "            self.indices.setdefault(int(iso), []).append(i)\n",
    "        self.keys = list(self.indices.keys())\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        keys = self.keys.copy()\n",
    "        if self.shuffle: random.shuffle(keys)\n",
    "        for k in keys:\n",
    "            yield self.indices[k]\n",
    "\n",
    "    def __len__(self): return len(self.keys)\n",
    "\n",
    "# ------------------------------ MODEL ---------------------------------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in:int, n_hidden:int, n_layers:int, p_drop:float):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for l in range(n_layers):\n",
    "            layers += [nn.Linear(n_in if l==0 else n_hidden, n_hidden),\n",
    "                       nn.ReLU(), nn.Dropout(p_drop)]\n",
    "        layers.append(nn.Linear(n_hidden, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x): return self.net(x).squeeze(1)\n",
    "\n",
    "# -------------------------- CUSTOM LOSS -------------------------------\n",
    "def iso_loss(batch, preds, lam:float):\n",
    "    mse = nn.functional.mse_loss(preds, batch[\"y\"])\n",
    "    if batch[\"gamma\"][0] == 0:     # skip σ₁g term if γ = 0\n",
    "        return mse\n",
    "    flu        = batch[\"fluence\"]\n",
    "    sigma_pred = (flu * preds).sum() / (flu.sum() + EPS)\n",
    "    sigma_true = batch[\"sigma_exp\"][0]\n",
    "    rel_err_sq = ((sigma_pred - sigma_true) / (sigma_true + EPS))**2\n",
    "    return mse + lam * rel_err_sq\n",
    "\n",
    "# ------------------------ TRAIN / VALID LOOP --------------------------\n",
    "def run_epoch(model, loader, opt, lam):\n",
    "    is_train = opt is not None\n",
    "    model.train(is_train)\n",
    "    total, n = 0.0, 0\n",
    "    for batch in loader:\n",
    "        batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                 for k,v in batch.items()}\n",
    "        preds = model(batch[\"x\"])\n",
    "        loss  = iso_loss(batch, preds, lam)\n",
    "        if is_train:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        total += loss.item() * len(preds)\n",
    "        n     += len(preds)\n",
    "    return total / n\n",
    "\n",
    "# ----------------------- PER-ISOTOPE ROUTINE --------------------------\n",
    "def process_isotope(df_all: pd.DataFrame, iso_hold: str) -> None:\n",
    "    out_dir = BASE_OUT / iso_hold\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df_test  = df_all[df_all[ISO] == iso_hold].reset_index(drop=True)\n",
    "    df_train = df_all[df_all[ISO] != iso_hold].reset_index(drop=True)\n",
    "    if df_test.empty:\n",
    "        print(f\"⚠  No rows for iso_id={iso_hold}; skipping.\")\n",
    "        return\n",
    "\n",
    "    preds_runs = []\n",
    "    for run in range(N_RUNS):\n",
    "        set_seed(SEED_BASE + run)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        ds_tr  = XSData(df_train, scaler, fit_scaler=True)\n",
    "        ds_te  = XSData(df_test,  scaler, fit_scaler=False)\n",
    "\n",
    "        dl_tr = DataLoader(ds_tr, batch_sampler=IsoBatchSampler(ds_tr.iso_code,\n",
    "                                                                shuffle=BATCH_SHUFFLE))\n",
    "        dl_te = DataLoader(ds_te, batch_sampler=IsoBatchSampler(ds_te.iso_code,\n",
    "                                                                shuffle=False))\n",
    "\n",
    "        model = MLP(len(FEATURES), N_HIDDEN, N_LAYERS, DROPOUT).to(DEVICE)\n",
    "        opt   = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "        best, patience = float(\"inf\"), 0\n",
    "        for _ in range(MAX_EPOCHS):\n",
    "            loss_tr = run_epoch(model, dl_tr, opt, LAM)\n",
    "            if loss_tr < best - 1e-6:\n",
    "                best, patience = loss_tr, 0\n",
    "            else:\n",
    "                patience += 1\n",
    "                if patience >= PATIENCE:\n",
    "                    break\n",
    "\n",
    "        # predict\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dl_te:\n",
    "                batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                         for k,v in batch.items()}\n",
    "                preds.append(model(batch[\"x\"]).cpu())\n",
    "        preds_runs.append(torch.cat(preds).numpy())\n",
    "\n",
    "    preds_arr  = np.stack(preds_runs, axis=1)\n",
    "    pred_mean  = preds_arr.mean(axis=1)\n",
    "\n",
    "    # save CSV ----------------------------------------------------------\n",
    "    df_out = pd.DataFrame({\"ERG\": df_test[\"ERG\"], \"XS_true\": df_test[\"XS\"]})\n",
    "    for r in range(N_RUNS):\n",
    "        df_out[f\"pred_run{r+1}\"] = preds_arr[:, r]\n",
    "    df_out[\"pred_mean\"] = pred_mean\n",
    "    csv_path = out_dir / f\"{iso_hold}_predictions.csv\"\n",
    "    df_out.to_csv(csv_path, index=False)\n",
    "\n",
    "    # plot --------------------------------------------------------------\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(df_out[\"ERG\"], df_out[\"XS_true\"],  lw=2, label=\"True XS\")\n",
    "    plt.plot(df_out[\"ERG\"], df_out[\"pred_mean\"], lw=2, ls=\"--\",\n",
    "             label=f\"Mean pred ({N_RUNS}×)\")\n",
    "    plt.xlabel(\"ERG\"); plt.ylabel(\"XS\")\n",
    "    plt.title(f\"{iso_hold} – true vs predicted XS\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(out_dir / f\"{iso_hold}_erg_vs_pred.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # meta --------------------------------------------------------------\n",
    "    meta = dict(lam=LAM, n_hidden=N_HIDDEN, n_layers=N_LAYERS,\n",
    "                dropout=DROPOUT, lr=LR, n_runs=N_RUNS,\n",
    "                iso_held_out=iso_hold)\n",
    "    with open(out_dir / \"run_meta.json\", \"w\") as fh:\n",
    "        json.dump(meta, fh, indent=2)\n",
    "\n",
    "    print(f\"✓ finished {iso_hold}\")\n",
    "\n",
    "# ------------------------------- MAIN ---------------------------------\n",
    "def main() -> None:\n",
    "    BASE_OUT.mkdir(parents=True, exist_ok=True)\n",
    "    df_all   = pd.read_csv(CSV_PATH)\n",
    "    iso_list = sorted(df_all[ISO].unique())\n",
    "\n",
    "    print(f\"Found {len(iso_list)} unique isotopes.\")\n",
    "    for iso in iso_list:\n",
    "        process_isotope(df_all, iso)\n",
    "\n",
    "    print(\"\\nAll isotopes done!\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------- IMPORTS ----------------------------------\n",
    "import random, pathlib, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------- CONSTANTS --------------------------------\n",
    "CSV_PATH   = \"merged_8_july_d_lowmassremoved.csv\"          # master dataset\n",
    "BASE_OUT   = pathlib.Path(\"results_lam0p2\")   # parent folder for all isotopes\n",
    "DEVICE     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ---- fixed hyper-parameters (λ = 0 run) ----\n",
    "LAM        = 0.2\n",
    "N_HIDDEN   = 32\n",
    "N_LAYERS   = 4\n",
    "DROPOUT    = 0.00043729211213425906\n",
    "LR         = 0.0006493008071290138\n",
    "\n",
    "MAX_EPOCHS = 200\n",
    "PATIENCE   = 15\n",
    "BATCH_SHUFFLE = True\n",
    "\n",
    "N_RUNS     = 10\n",
    "SEED_BASE  = 1234\n",
    "EPS        = 1e-12\n",
    "\n",
    "FEATURES = [\n",
    "    'ERG','Radius','n_rms_radius','p_rms_radius','octopole_deformation',\n",
    "    'n_chem_erg','Sn','Z','S2p_compound','gamma_deformation','ME',\n",
    "    'BEA_A_daughter','A','Radius_daughter','BEA_A','AM','Radius_compound',\n",
    "    'Pairing_daughter','BEA_compound','beta_deformation','Theory_thresh',\n",
    "    'shell_P','pairing_delta','symmetry_S','excitation_energy',\n",
    "    'Thresh_n3n','Excite_n3n','Thresh_n4n','Excite_n4n'\n",
    "]\n",
    "TARGET, SIGMA_EXP, FLUENCE, GAMMA, ISO = (\n",
    "    \"XS\",\"sigma_exp\",\"fluence\",\"gamma\",\"iso_id\"\n",
    ")\n",
    "\n",
    "# --------------------------- UTILITIES --------------------------------\n",
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# ----------------------- DATASET & SAMPLER ----------------------------\n",
    "class XSData(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, scaler: StandardScaler,\n",
    "                 fit_scaler: bool = False):\n",
    "        if fit_scaler:\n",
    "            scaler.fit(df[FEATURES])\n",
    "        self.X = torch.tensor(scaler.transform(df[FEATURES]).astype(np.float32))\n",
    "        self.y = torch.tensor(df[TARGET].to_numpy(np.float32))\n",
    "        self.fluence   = torch.tensor(df[FLUENCE].to_numpy(np.float32))\n",
    "        self.sigma_exp = torch.tensor(df[SIGMA_EXP].fillna(0).to_numpy(np.float32))\n",
    "        self.gamma     = torch.tensor(df[GAMMA].to_numpy(np.float32))\n",
    "        self.iso_code  = df[ISO].astype(\"category\").cat.codes.to_numpy()\n",
    "\n",
    "    def __len__(self): return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return {\"x\": self.X[idx], \"y\": self.y[idx],\n",
    "                \"fluence\": self.fluence[idx],\n",
    "                \"sigma_exp\": self.sigma_exp[idx],\n",
    "                \"gamma\": self.gamma[idx],\n",
    "                \"iso_code\": self.iso_code[idx]}\n",
    "\n",
    "class IsoBatchSampler(Sampler):\n",
    "    def __init__(self, iso_codes, shuffle=True):\n",
    "        self.indices = {}\n",
    "        for i, iso in enumerate(iso_codes):\n",
    "            self.indices.setdefault(int(iso), []).append(i)\n",
    "        self.keys = list(self.indices.keys())\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        keys = self.keys.copy()\n",
    "        if self.shuffle: random.shuffle(keys)\n",
    "        for k in keys:\n",
    "            yield self.indices[k]\n",
    "\n",
    "    def __len__(self): return len(self.keys)\n",
    "\n",
    "# ------------------------------ MODEL ---------------------------------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in:int, n_hidden:int, n_layers:int, p_drop:float):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for l in range(n_layers):\n",
    "            layers += [nn.Linear(n_in if l==0 else n_hidden, n_hidden),\n",
    "                       nn.ReLU(), nn.Dropout(p_drop)]\n",
    "        layers.append(nn.Linear(n_hidden, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x): return self.net(x).squeeze(1)\n",
    "\n",
    "# -------------------------- CUSTOM LOSS -------------------------------\n",
    "def iso_loss(batch, preds, lam:float):\n",
    "    mse = nn.functional.mse_loss(preds, batch[\"y\"])\n",
    "    if batch[\"gamma\"][0] == 0:     # skip σ₁g term if γ = 0\n",
    "        return mse\n",
    "    flu        = batch[\"fluence\"]\n",
    "    sigma_pred = (flu * preds).sum() / (flu.sum() + EPS)\n",
    "    sigma_true = batch[\"sigma_exp\"][0]\n",
    "    rel_err_sq = ((sigma_pred - sigma_true) / (sigma_true + EPS))**2\n",
    "    return mse + lam * rel_err_sq\n",
    "\n",
    "# ------------------------ TRAIN / VALID LOOP --------------------------\n",
    "def run_epoch(model, loader, opt, lam):\n",
    "    is_train = opt is not None\n",
    "    model.train(is_train)\n",
    "    total, n = 0.0, 0\n",
    "    for batch in loader:\n",
    "        batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                 for k,v in batch.items()}\n",
    "        preds = model(batch[\"x\"])\n",
    "        loss  = iso_loss(batch, preds, lam)\n",
    "        if is_train:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        total += loss.item() * len(preds)\n",
    "        n     += len(preds)\n",
    "    return total / n\n",
    "\n",
    "# ----------------------- PER-ISOTOPE ROUTINE --------------------------\n",
    "def process_isotope(df_all: pd.DataFrame, iso_hold: str) -> None:\n",
    "    out_dir = BASE_OUT / iso_hold\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df_test  = df_all[df_all[ISO] == iso_hold].reset_index(drop=True)\n",
    "    df_train = df_all[df_all[ISO] != iso_hold].reset_index(drop=True)\n",
    "    if df_test.empty:\n",
    "        print(f\"⚠  No rows for iso_id={iso_hold}; skipping.\")\n",
    "        return\n",
    "\n",
    "    preds_runs = []\n",
    "    for run in range(N_RUNS):\n",
    "        set_seed(SEED_BASE + run)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        ds_tr  = XSData(df_train, scaler, fit_scaler=True)\n",
    "        ds_te  = XSData(df_test,  scaler, fit_scaler=False)\n",
    "\n",
    "        dl_tr = DataLoader(ds_tr, batch_sampler=IsoBatchSampler(ds_tr.iso_code,\n",
    "                                                                shuffle=BATCH_SHUFFLE))\n",
    "        dl_te = DataLoader(ds_te, batch_sampler=IsoBatchSampler(ds_te.iso_code,\n",
    "                                                                shuffle=False))\n",
    "\n",
    "        model = MLP(len(FEATURES), N_HIDDEN, N_LAYERS, DROPOUT).to(DEVICE)\n",
    "        opt   = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "        best, patience = float(\"inf\"), 0\n",
    "        for _ in range(MAX_EPOCHS):\n",
    "            loss_tr = run_epoch(model, dl_tr, opt, LAM)\n",
    "            if loss_tr < best - 1e-6:\n",
    "                best, patience = loss_tr, 0\n",
    "            else:\n",
    "                patience += 1\n",
    "                if patience >= PATIENCE:\n",
    "                    break\n",
    "\n",
    "        # predict\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dl_te:\n",
    "                batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                         for k,v in batch.items()}\n",
    "                preds.append(model(batch[\"x\"]).cpu())\n",
    "        preds_runs.append(torch.cat(preds).numpy())\n",
    "\n",
    "    preds_arr  = np.stack(preds_runs, axis=1)\n",
    "    pred_mean  = preds_arr.mean(axis=1)\n",
    "\n",
    "    # save CSV ----------------------------------------------------------\n",
    "    df_out = pd.DataFrame({\"ERG\": df_test[\"ERG\"], \"XS_true\": df_test[\"XS\"]})\n",
    "    for r in range(N_RUNS):\n",
    "        df_out[f\"pred_run{r+1}\"] = preds_arr[:, r]\n",
    "    df_out[\"pred_mean\"] = pred_mean\n",
    "    csv_path = out_dir / f\"{iso_hold}_predictions.csv\"\n",
    "    df_out.to_csv(csv_path, index=False)\n",
    "\n",
    "    # plot --------------------------------------------------------------\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(df_out[\"ERG\"], df_out[\"XS_true\"],  lw=2, label=\"True XS\")\n",
    "    plt.plot(df_out[\"ERG\"], df_out[\"pred_mean\"], lw=2, ls=\"--\",\n",
    "             label=f\"Mean pred ({N_RUNS}×)\")\n",
    "    plt.xlabel(\"ERG\"); plt.ylabel(\"XS\")\n",
    "    plt.title(f\"{iso_hold} – true vs predicted XS\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(out_dir / f\"{iso_hold}_erg_vs_pred.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # meta --------------------------------------------------------------\n",
    "    meta = dict(lam=LAM, n_hidden=N_HIDDEN, n_layers=N_LAYERS,\n",
    "                dropout=DROPOUT, lr=LR, n_runs=N_RUNS,\n",
    "                iso_held_out=iso_hold)\n",
    "    with open(out_dir / \"run_meta.json\", \"w\") as fh:\n",
    "        json.dump(meta, fh, indent=2)\n",
    "\n",
    "    print(f\"✓ finished {iso_hold}\")\n",
    "\n",
    "# ------------------------------- MAIN ---------------------------------\n",
    "def main() -> None:\n",
    "    BASE_OUT.mkdir(parents=True, exist_ok=True)\n",
    "    df_all   = pd.read_csv(CSV_PATH)\n",
    "    iso_list = sorted(df_all[ISO].unique())\n",
    "\n",
    "    print(f\"Found {len(iso_list)} unique isotopes.\")\n",
    "    for iso in iso_list:\n",
    "        process_isotope(df_all, iso)\n",
    "\n",
    "    print(\"\\nAll isotopes done!\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------------- IMPORTS ----------------------------------\n",
    "import random, pathlib, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------- CONSTANTS --------------------------------\n",
    "CSV_PATH   = \"merged_8_july_d_lowmassremoved.csv\"          # master dataset\n",
    "BASE_OUT   = pathlib.Path(\"results_lam0p3\")   # parent folder for all isotopes\n",
    "DEVICE     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "LAM        = 0.3\n",
    "N_HIDDEN   = 96\n",
    "N_LAYERS   = 2\n",
    "DROPOUT    = 0.08283102638417343\n",
    "LR         = 0.0013388761576798537\n",
    "\n",
    "MAX_EPOCHS = 200\n",
    "PATIENCE   = 15\n",
    "BATCH_SHUFFLE = True\n",
    "\n",
    "N_RUNS     = 10\n",
    "SEED_BASE  = 1234\n",
    "EPS        = 1e-12\n",
    "\n",
    "FEATURES = [\n",
    "    'ERG','Radius','n_rms_radius','p_rms_radius','octopole_deformation',\n",
    "    'n_chem_erg','Sn','Z','S2p_compound','gamma_deformation','ME',\n",
    "    'BEA_A_daughter','A','Radius_daughter','BEA_A','AM','Radius_compound',\n",
    "    'Pairing_daughter','BEA_compound','beta_deformation','Theory_thresh',\n",
    "    'shell_P','pairing_delta','symmetry_S','excitation_energy',\n",
    "    'Thresh_n3n','Excite_n3n','Thresh_n4n','Excite_n4n'\n",
    "]\n",
    "TARGET, SIGMA_EXP, FLUENCE, GAMMA, ISO = (\n",
    "    \"XS\",\"sigma_exp\",\"fluence\",\"gamma\",\"iso_id\"\n",
    ")\n",
    "\n",
    "# --------------------------- UTILITIES --------------------------------\n",
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# ----------------------- DATASET & SAMPLER ----------------------------\n",
    "class XSData(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, scaler: StandardScaler,\n",
    "                 fit_scaler: bool = False):\n",
    "        if fit_scaler:\n",
    "            scaler.fit(df[FEATURES])\n",
    "        self.X = torch.tensor(scaler.transform(df[FEATURES]).astype(np.float32))\n",
    "        self.y = torch.tensor(df[TARGET].to_numpy(np.float32))\n",
    "        self.fluence   = torch.tensor(df[FLUENCE].to_numpy(np.float32))\n",
    "        self.sigma_exp = torch.tensor(df[SIGMA_EXP].fillna(0).to_numpy(np.float32))\n",
    "        self.gamma     = torch.tensor(df[GAMMA].to_numpy(np.float32))\n",
    "        self.iso_code  = df[ISO].astype(\"category\").cat.codes.to_numpy()\n",
    "\n",
    "    def __len__(self): return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return {\"x\": self.X[idx], \"y\": self.y[idx],\n",
    "                \"fluence\": self.fluence[idx],\n",
    "                \"sigma_exp\": self.sigma_exp[idx],\n",
    "                \"gamma\": self.gamma[idx],\n",
    "                \"iso_code\": self.iso_code[idx]}\n",
    "\n",
    "class IsoBatchSampler(Sampler):\n",
    "    def __init__(self, iso_codes, shuffle=True):\n",
    "        self.indices = {}\n",
    "        for i, iso in enumerate(iso_codes):\n",
    "            self.indices.setdefault(int(iso), []).append(i)\n",
    "        self.keys = list(self.indices.keys())\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        keys = self.keys.copy()\n",
    "        if self.shuffle: random.shuffle(keys)\n",
    "        for k in keys:\n",
    "            yield self.indices[k]\n",
    "\n",
    "    def __len__(self): return len(self.keys)\n",
    "\n",
    "# ------------------------------ MODEL ---------------------------------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in:int, n_hidden:int, n_layers:int, p_drop:float):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for l in range(n_layers):\n",
    "            layers += [nn.Linear(n_in if l==0 else n_hidden, n_hidden),\n",
    "                       nn.ReLU(), nn.Dropout(p_drop)]\n",
    "        layers.append(nn.Linear(n_hidden, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x): return self.net(x).squeeze(1)\n",
    "\n",
    "# -------------------------- CUSTOM LOSS -------------------------------\n",
    "def iso_loss(batch, preds, lam:float):\n",
    "    mse = nn.functional.mse_loss(preds, batch[\"y\"])\n",
    "    if batch[\"gamma\"][0] == 0:     # skip σ₁g term if γ = 0\n",
    "        return mse\n",
    "    flu        = batch[\"fluence\"]\n",
    "    sigma_pred = (flu * preds).sum() / (flu.sum() + EPS)\n",
    "    sigma_true = batch[\"sigma_exp\"][0]\n",
    "    rel_err_sq = ((sigma_pred - sigma_true) / (sigma_true + EPS))**2\n",
    "    return mse + lam * rel_err_sq\n",
    "\n",
    "# ------------------------ TRAIN / VALID LOOP --------------------------\n",
    "def run_epoch(model, loader, opt, lam):\n",
    "    is_train = opt is not None\n",
    "    model.train(is_train)\n",
    "    total, n = 0.0, 0\n",
    "    for batch in loader:\n",
    "        batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                 for k,v in batch.items()}\n",
    "        preds = model(batch[\"x\"])\n",
    "        loss  = iso_loss(batch, preds, lam)\n",
    "        if is_train:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        total += loss.item() * len(preds)\n",
    "        n     += len(preds)\n",
    "    return total / n\n",
    "\n",
    "# ----------------------- PER-ISOTOPE ROUTINE --------------------------\n",
    "def process_isotope(df_all: pd.DataFrame, iso_hold: str) -> None:\n",
    "    out_dir = BASE_OUT / iso_hold\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df_test  = df_all[df_all[ISO] == iso_hold].reset_index(drop=True)\n",
    "    df_train = df_all[df_all[ISO] != iso_hold].reset_index(drop=True)\n",
    "    if df_test.empty:\n",
    "        print(f\"⚠  No rows for iso_id={iso_hold}; skipping.\")\n",
    "        return\n",
    "\n",
    "    preds_runs = []\n",
    "    for run in range(N_RUNS):\n",
    "        set_seed(SEED_BASE + run)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        ds_tr  = XSData(df_train, scaler, fit_scaler=True)\n",
    "        ds_te  = XSData(df_test,  scaler, fit_scaler=False)\n",
    "\n",
    "        dl_tr = DataLoader(ds_tr, batch_sampler=IsoBatchSampler(ds_tr.iso_code,\n",
    "                                                                shuffle=BATCH_SHUFFLE))\n",
    "        dl_te = DataLoader(ds_te, batch_sampler=IsoBatchSampler(ds_te.iso_code,\n",
    "                                                                shuffle=False))\n",
    "\n",
    "        model = MLP(len(FEATURES), N_HIDDEN, N_LAYERS, DROPOUT).to(DEVICE)\n",
    "        opt   = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "        best, patience = float(\"inf\"), 0\n",
    "        for _ in range(MAX_EPOCHS):\n",
    "            loss_tr = run_epoch(model, dl_tr, opt, LAM)\n",
    "            if loss_tr < best - 1e-6:\n",
    "                best, patience = loss_tr, 0\n",
    "            else:\n",
    "                patience += 1\n",
    "                if patience >= PATIENCE:\n",
    "                    break\n",
    "\n",
    "        # predict\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dl_te:\n",
    "                batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                         for k,v in batch.items()}\n",
    "                preds.append(model(batch[\"x\"]).cpu())\n",
    "        preds_runs.append(torch.cat(preds).numpy())\n",
    "\n",
    "    preds_arr  = np.stack(preds_runs, axis=1)\n",
    "    pred_mean  = preds_arr.mean(axis=1)\n",
    "\n",
    "    # save CSV ----------------------------------------------------------\n",
    "    df_out = pd.DataFrame({\"ERG\": df_test[\"ERG\"], \"XS_true\": df_test[\"XS\"]})\n",
    "    for r in range(N_RUNS):\n",
    "        df_out[f\"pred_run{r+1}\"] = preds_arr[:, r]\n",
    "    df_out[\"pred_mean\"] = pred_mean\n",
    "    csv_path = out_dir / f\"{iso_hold}_predictions.csv\"\n",
    "    df_out.to_csv(csv_path, index=False)\n",
    "\n",
    "    # plot --------------------------------------------------------------\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(df_out[\"ERG\"], df_out[\"XS_true\"],  lw=2, label=\"True XS\")\n",
    "    plt.plot(df_out[\"ERG\"], df_out[\"pred_mean\"], lw=2, ls=\"--\",\n",
    "             label=f\"Mean pred ({N_RUNS}×)\")\n",
    "    plt.xlabel(\"ERG\"); plt.ylabel(\"XS\")\n",
    "    plt.title(f\"{iso_hold} – true vs predicted XS\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(out_dir / f\"{iso_hold}_erg_vs_pred.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # meta --------------------------------------------------------------\n",
    "    meta = dict(lam=LAM, n_hidden=N_HIDDEN, n_layers=N_LAYERS,\n",
    "                dropout=DROPOUT, lr=LR, n_runs=N_RUNS,\n",
    "                iso_held_out=iso_hold)\n",
    "    with open(out_dir / \"run_meta.json\", \"w\") as fh:\n",
    "        json.dump(meta, fh, indent=2)\n",
    "\n",
    "    print(f\"✓ finished {iso_hold}\")\n",
    "\n",
    "# ------------------------------- MAIN ---------------------------------\n",
    "def main() -> None:\n",
    "    BASE_OUT.mkdir(parents=True, exist_ok=True)\n",
    "    df_all   = pd.read_csv(CSV_PATH)\n",
    "    iso_list = sorted(df_all[ISO].unique())\n",
    "\n",
    "    print(f\"Found {len(iso_list)} unique isotopes.\")\n",
    "    for iso in iso_list:\n",
    "        process_isotope(df_all, iso)\n",
    "\n",
    "    print(\"\\nAll isotopes done!\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- IMPORTS ----------------------------------\n",
    "import random, pathlib, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------- CONSTANTS --------------------------------\n",
    "CSV_PATH   = \"merged_8_july_d_lowmassremoved.csv\"          # master dataset\n",
    "BASE_OUT   = pathlib.Path(\"results_lam0p4\")   # parent folder for all isotopes\n",
    "DEVICE     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "LAM        = 0.4\n",
    "N_HIDDEN   = 96\n",
    "N_LAYERS   = 2\n",
    "DROPOUT    = 0.032508366621761715\n",
    "LR         = 0.0006684238765748816\n",
    "\n",
    "MAX_EPOCHS = 200\n",
    "PATIENCE   = 15\n",
    "BATCH_SHUFFLE = True\n",
    "\n",
    "N_RUNS     = 10\n",
    "SEED_BASE  = 1234\n",
    "EPS        = 1e-12\n",
    "\n",
    "FEATURES = [\n",
    "    'ERG','Radius','n_rms_radius','p_rms_radius','octopole_deformation',\n",
    "    'n_chem_erg','Sn','Z','S2p_compound','gamma_deformation','ME',\n",
    "    'BEA_A_daughter','A','Radius_daughter','BEA_A','AM','Radius_compound',\n",
    "    'Pairing_daughter','BEA_compound','beta_deformation','Theory_thresh',\n",
    "    'shell_P','pairing_delta','symmetry_S','excitation_energy',\n",
    "    'Thresh_n3n','Excite_n3n','Thresh_n4n','Excite_n4n'\n",
    "]\n",
    "TARGET, SIGMA_EXP, FLUENCE, GAMMA, ISO = (\n",
    "    \"XS\",\"sigma_exp\",\"fluence\",\"gamma\",\"iso_id\"\n",
    ")\n",
    "\n",
    "# --------------------------- UTILITIES --------------------------------\n",
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# ----------------------- DATASET & SAMPLER ----------------------------\n",
    "class XSData(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, scaler: StandardScaler,\n",
    "                 fit_scaler: bool = False):\n",
    "        if fit_scaler:\n",
    "            scaler.fit(df[FEATURES])\n",
    "        self.X = torch.tensor(scaler.transform(df[FEATURES]).astype(np.float32))\n",
    "        self.y = torch.tensor(df[TARGET].to_numpy(np.float32))\n",
    "        self.fluence   = torch.tensor(df[FLUENCE].to_numpy(np.float32))\n",
    "        self.sigma_exp = torch.tensor(df[SIGMA_EXP].fillna(0).to_numpy(np.float32))\n",
    "        self.gamma     = torch.tensor(df[GAMMA].to_numpy(np.float32))\n",
    "        self.iso_code  = df[ISO].astype(\"category\").cat.codes.to_numpy()\n",
    "\n",
    "    def __len__(self): return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return {\"x\": self.X[idx], \"y\": self.y[idx],\n",
    "                \"fluence\": self.fluence[idx],\n",
    "                \"sigma_exp\": self.sigma_exp[idx],\n",
    "                \"gamma\": self.gamma[idx],\n",
    "                \"iso_code\": self.iso_code[idx]}\n",
    "\n",
    "class IsoBatchSampler(Sampler):\n",
    "    def __init__(self, iso_codes, shuffle=True):\n",
    "        self.indices = {}\n",
    "        for i, iso in enumerate(iso_codes):\n",
    "            self.indices.setdefault(int(iso), []).append(i)\n",
    "        self.keys = list(self.indices.keys())\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        keys = self.keys.copy()\n",
    "        if self.shuffle: random.shuffle(keys)\n",
    "        for k in keys:\n",
    "            yield self.indices[k]\n",
    "\n",
    "    def __len__(self): return len(self.keys)\n",
    "\n",
    "# ------------------------------ MODEL ---------------------------------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in:int, n_hidden:int, n_layers:int, p_drop:float):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for l in range(n_layers):\n",
    "            layers += [nn.Linear(n_in if l==0 else n_hidden, n_hidden),\n",
    "                       nn.ReLU(), nn.Dropout(p_drop)]\n",
    "        layers.append(nn.Linear(n_hidden, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x): return self.net(x).squeeze(1)\n",
    "\n",
    "# -------------------------- CUSTOM LOSS -------------------------------\n",
    "def iso_loss(batch, preds, lam:float):\n",
    "    mse = nn.functional.mse_loss(preds, batch[\"y\"])\n",
    "    if batch[\"gamma\"][0] == 0:     # skip σ₁g term if γ = 0\n",
    "        return mse\n",
    "    flu        = batch[\"fluence\"]\n",
    "    sigma_pred = (flu * preds).sum() / (flu.sum() + EPS)\n",
    "    sigma_true = batch[\"sigma_exp\"][0]\n",
    "    rel_err_sq = ((sigma_pred - sigma_true) / (sigma_true + EPS))**2\n",
    "    return mse + lam * rel_err_sq\n",
    "\n",
    "# ------------------------ TRAIN / VALID LOOP --------------------------\n",
    "def run_epoch(model, loader, opt, lam):\n",
    "    is_train = opt is not None\n",
    "    model.train(is_train)\n",
    "    total, n = 0.0, 0\n",
    "    for batch in loader:\n",
    "        batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                 for k,v in batch.items()}\n",
    "        preds = model(batch[\"x\"])\n",
    "        loss  = iso_loss(batch, preds, lam)\n",
    "        if is_train:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        total += loss.item() * len(preds)\n",
    "        n     += len(preds)\n",
    "    return total / n\n",
    "\n",
    "# ----------------------- PER-ISOTOPE ROUTINE --------------------------\n",
    "def process_isotope(df_all: pd.DataFrame, iso_hold: str) -> None:\n",
    "    out_dir = BASE_OUT / iso_hold\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df_test  = df_all[df_all[ISO] == iso_hold].reset_index(drop=True)\n",
    "    df_train = df_all[df_all[ISO] != iso_hold].reset_index(drop=True)\n",
    "    if df_test.empty:\n",
    "        print(f\"⚠  No rows for iso_id={iso_hold}; skipping.\")\n",
    "        return\n",
    "\n",
    "    preds_runs = []\n",
    "    for run in range(N_RUNS):\n",
    "        set_seed(SEED_BASE + run)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        ds_tr  = XSData(df_train, scaler, fit_scaler=True)\n",
    "        ds_te  = XSData(df_test,  scaler, fit_scaler=False)\n",
    "\n",
    "        dl_tr = DataLoader(ds_tr, batch_sampler=IsoBatchSampler(ds_tr.iso_code,\n",
    "                                                                shuffle=BATCH_SHUFFLE))\n",
    "        dl_te = DataLoader(ds_te, batch_sampler=IsoBatchSampler(ds_te.iso_code,\n",
    "                                                                shuffle=False))\n",
    "\n",
    "        model = MLP(len(FEATURES), N_HIDDEN, N_LAYERS, DROPOUT).to(DEVICE)\n",
    "        opt   = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "        best, patience = float(\"inf\"), 0\n",
    "        for _ in range(MAX_EPOCHS):\n",
    "            loss_tr = run_epoch(model, dl_tr, opt, LAM)\n",
    "            if loss_tr < best - 1e-6:\n",
    "                best, patience = loss_tr, 0\n",
    "            else:\n",
    "                patience += 1\n",
    "                if patience >= PATIENCE:\n",
    "                    break\n",
    "\n",
    "        # predict\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dl_te:\n",
    "                batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                         for k,v in batch.items()}\n",
    "                preds.append(model(batch[\"x\"]).cpu())\n",
    "        preds_runs.append(torch.cat(preds).numpy())\n",
    "\n",
    "    preds_arr  = np.stack(preds_runs, axis=1)\n",
    "    pred_mean  = preds_arr.mean(axis=1)\n",
    "\n",
    "    # save CSV ----------------------------------------------------------\n",
    "    df_out = pd.DataFrame({\"ERG\": df_test[\"ERG\"], \"XS_true\": df_test[\"XS\"]})\n",
    "    for r in range(N_RUNS):\n",
    "        df_out[f\"pred_run{r+1}\"] = preds_arr[:, r]\n",
    "    df_out[\"pred_mean\"] = pred_mean\n",
    "    csv_path = out_dir / f\"{iso_hold}_predictions.csv\"\n",
    "    df_out.to_csv(csv_path, index=False)\n",
    "\n",
    "    # plot --------------------------------------------------------------\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(df_out[\"ERG\"], df_out[\"XS_true\"],  lw=2, label=\"True XS\")\n",
    "    plt.plot(df_out[\"ERG\"], df_out[\"pred_mean\"], lw=2, ls=\"--\",\n",
    "             label=f\"Mean pred ({N_RUNS}×)\")\n",
    "    plt.xlabel(\"ERG\"); plt.ylabel(\"XS\")\n",
    "    plt.title(f\"{iso_hold} – true vs predicted XS\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(out_dir / f\"{iso_hold}_erg_vs_pred.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # meta --------------------------------------------------------------\n",
    "    meta = dict(lam=LAM, n_hidden=N_HIDDEN, n_layers=N_LAYERS,\n",
    "                dropout=DROPOUT, lr=LR, n_runs=N_RUNS,\n",
    "                iso_held_out=iso_hold)\n",
    "    with open(out_dir / \"run_meta.json\", \"w\") as fh:\n",
    "        json.dump(meta, fh, indent=2)\n",
    "\n",
    "    print(f\"✓ finished {iso_hold}\")\n",
    "\n",
    "# ------------------------------- MAIN ---------------------------------\n",
    "def main() -> None:\n",
    "    BASE_OUT.mkdir(parents=True, exist_ok=True)\n",
    "    df_all   = pd.read_csv(CSV_PATH)\n",
    "    iso_list = sorted(df_all[ISO].unique())\n",
    "\n",
    "    print(f\"Found {len(iso_list)} unique isotopes.\")\n",
    "    for iso in iso_list:\n",
    "        process_isotope(df_all, iso)\n",
    "\n",
    "    print(\"\\nAll isotopes done!\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --------------------------- IMPORTS ----------------------------------\n",
    "import os, random, pathlib, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------- CONSTANTS --------------------------------\n",
    "CSV_PATH   = \"merged_8_july_d_lowmassremoved.csv\"       # master data file\n",
    "BASE_OUT   = pathlib.Path(\"results_lam0p5\")  # parent folder for all isotopes\n",
    "DEVICE     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "LAM        = 0.5\n",
    "N_HIDDEN   = 160\n",
    "N_LAYERS   = 4\n",
    "DROPOUT    = 0.00811351363377738\n",
    "LR         = 1.6705487638549014e-4\n",
    "\n",
    "MAX_EPOCHS = 200\n",
    "PATIENCE   = 15\n",
    "BATCH_SHUFFLE = True\n",
    "\n",
    "N_RUNS     = 10\n",
    "SEED_BASE  = 1234\n",
    "EPS        = 1e-12\n",
    "\n",
    "FEATURES = [\n",
    "    'ERG','Radius','n_rms_radius','p_rms_radius','octopole_deformation',\n",
    "    'n_chem_erg','Sn','Z','S2p_compound','gamma_deformation','ME',\n",
    "    'BEA_A_daughter','A','Radius_daughter','BEA_A','AM','Radius_compound',\n",
    "    'Pairing_daughter','BEA_compound','beta_deformation','Theory_thresh',\n",
    "    'shell_P','pairing_delta','symmetry_S','excitation_energy',\n",
    "    'Thresh_n3n','Excite_n3n','Thresh_n4n','Excite_n4n'\n",
    "]\n",
    "TARGET, SIGMA_EXP, FLUENCE, GAMMA, ISO = (\n",
    "    \"XS\",\"sigma_exp\",\"fluence\",\"gamma\",\"iso_id\"\n",
    ")\n",
    "\n",
    "# --------------------------- UTILITIES --------------------------------\n",
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# ----------------------- DATASET & SAMPLER ----------------------------\n",
    "class XSData(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, scaler: StandardScaler,\n",
    "                 fit_scaler: bool = False):\n",
    "        if fit_scaler:\n",
    "            scaler.fit(df[FEATURES])\n",
    "        self.X = torch.tensor(scaler.transform(df[FEATURES]).astype(np.float32))\n",
    "        self.y = torch.tensor(df[TARGET].to_numpy(np.float32))\n",
    "        self.fluence    = torch.tensor(df[FLUENCE].to_numpy(np.float32))\n",
    "        self.sigma_exp  = torch.tensor(df[SIGMA_EXP].fillna(0).to_numpy(np.float32))\n",
    "        self.gamma      = torch.tensor(df[GAMMA].to_numpy(np.float32))\n",
    "        self.iso_code   = df[ISO].astype(\"category\").cat.codes.to_numpy()\n",
    "\n",
    "    def __len__(self): return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"x\":          self.X[idx],\n",
    "            \"y\":          self.y[idx],\n",
    "            \"fluence\":    self.fluence[idx],\n",
    "            \"sigma_exp\":  self.sigma_exp[idx],\n",
    "            \"gamma\":      self.gamma[idx],\n",
    "            \"iso_code\":   self.iso_code[idx]\n",
    "        }\n",
    "\n",
    "class IsoBatchSampler(Sampler):\n",
    "    def __init__(self, iso_codes, shuffle=True):\n",
    "        self.indices = {}\n",
    "        for i, iso in enumerate(iso_codes):\n",
    "            self.indices.setdefault(int(iso), []).append(i)\n",
    "        self.keys = list(self.indices.keys())\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        keys = self.keys.copy()\n",
    "        if self.shuffle: random.shuffle(keys)\n",
    "        for k in keys:\n",
    "            yield self.indices[k]\n",
    "\n",
    "    def __len__(self): return len(self.keys)\n",
    "\n",
    "# ------------------------------ MODEL ---------------------------------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, n_hidden, n_layers, p_drop):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for l in range(n_layers):\n",
    "            layers += [\n",
    "                nn.Linear(n_in if l==0 else n_hidden, n_hidden),\n",
    "                nn.ReLU(), nn.Dropout(p_drop)\n",
    "            ]\n",
    "        layers.append(nn.Linear(n_hidden, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x): return self.net(x).squeeze(1)\n",
    "\n",
    "# -------------------------- CUSTOM LOSS -------------------------------\n",
    "def iso_loss(batch, preds, lam):\n",
    "    mse = nn.functional.mse_loss(preds, batch[\"y\"])\n",
    "    if batch[\"gamma\"][0] == 0:\n",
    "        return mse\n",
    "    flu         = batch[\"fluence\"]\n",
    "    sigma_pred  = (flu * preds).sum() / (flu.sum() + EPS)\n",
    "    sigma_true  = batch[\"sigma_exp\"][0]\n",
    "    rel_err_sq  = ((sigma_pred - sigma_true) / (sigma_true + EPS)) ** 2\n",
    "    return mse + lam * rel_err_sq\n",
    "\n",
    "# ------------------------ TRAIN / VALID LOOP --------------------------\n",
    "def run_epoch(model, loader, opt, lam):\n",
    "    is_train = opt is not None\n",
    "    model.train(is_train)\n",
    "    total, n = 0.0, 0\n",
    "    for batch in loader:\n",
    "        batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                 for k,v in batch.items()}\n",
    "        preds = model(batch[\"x\"])\n",
    "        loss  = iso_loss(batch, preds, lam)\n",
    "        if is_train:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        total += loss.item() * len(preds)\n",
    "        n     += len(preds)\n",
    "    return total / n\n",
    "\n",
    "# ----------------------- PER-ISOTOPE PIPELINE -------------------------\n",
    "def process_isotope(df_all: pd.DataFrame, iso_hold: str) -> None:\n",
    "    out_dir = BASE_OUT / iso_hold\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df_test  = df_all[df_all[ISO] == iso_hold].reset_index(drop=True)\n",
    "    df_train = df_all[df_all[ISO] != iso_hold].reset_index(drop=True)\n",
    "    if df_test.empty:\n",
    "        print(f\"⚠  No rows for iso_id={iso_hold}; skipping.\")\n",
    "        return\n",
    "\n",
    "    all_preds = []\n",
    "    for run in range(N_RUNS):\n",
    "        set_seed(SEED_BASE + run)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        ds_tr  = XSData(df_train, scaler, fit_scaler=True)\n",
    "        ds_te  = XSData(df_test,  scaler, fit_scaler=False)\n",
    "\n",
    "        dl_tr = DataLoader(ds_tr, batch_sampler=IsoBatchSampler(ds_tr.iso_code,\n",
    "                                                                shuffle=BATCH_SHUFFLE))\n",
    "        dl_te = DataLoader(ds_te, batch_sampler=IsoBatchSampler(ds_te.iso_code,\n",
    "                                                                shuffle=False))\n",
    "\n",
    "        model = MLP(len(FEATURES), N_HIDDEN, N_LAYERS, DROPOUT).to(DEVICE)\n",
    "        opt   = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "        best, patience = float(\"inf\"), 0\n",
    "        for ep in range(MAX_EPOCHS):\n",
    "            loss_tr = run_epoch(model, dl_tr, opt, LAM)\n",
    "            if loss_tr < best - 1e-6:\n",
    "                best, patience = loss_tr, 0\n",
    "            else:\n",
    "                patience += 1\n",
    "                if patience >= PATIENCE: break\n",
    "\n",
    "        # predict\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dl_te:\n",
    "                batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                         for k,v in batch.items()}\n",
    "                preds.append(model(batch[\"x\"]).cpu())\n",
    "        all_preds.append(torch.cat(preds).numpy())\n",
    "\n",
    "    preds_arr = np.stack(all_preds, axis=1)\n",
    "    pred_mean = preds_arr.mean(axis=1)\n",
    "\n",
    "    out_df = pd.DataFrame({\"ERG\": df_test[\"ERG\"], \"XS_true\": df_test[\"XS\"]})\n",
    "    for r in range(N_RUNS):\n",
    "        out_df[f\"pred_run{r+1}\"] = preds_arr[:, r]\n",
    "    out_df[\"pred_mean\"] = pred_mean\n",
    "\n",
    "    csv_path = out_dir / f\"{iso_hold}_predictions.csv\"\n",
    "    out_df.to_csv(csv_path, index=False)\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(out_df[\"ERG\"], out_df[\"XS_true\"], lw=2, label=\"True XS\")\n",
    "    plt.plot(out_df[\"ERG\"], out_df[\"pred_mean\"], lw=2, ls=\"--\",\n",
    "             label=f\"Mean pred ({N_RUNS}×)\")\n",
    "    plt.xlabel(\"ERG\"); plt.ylabel(\"XS\")\n",
    "    plt.title(f\"{iso_hold} – true vs predicted XS\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(out_dir / f\"{iso_hold}_erg_vs_pred.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # meta\n",
    "    meta = dict(lam=LAM, n_hidden=N_HIDDEN, n_layers=N_LAYERS,\n",
    "                dropout=DROPOUT, lr=LR, n_runs=N_RUNS,\n",
    "                iso_held_out=iso_hold)\n",
    "    with open(out_dir / \"run_meta.json\", \"w\") as fh:\n",
    "        json.dump(meta, fh, indent=2)\n",
    "\n",
    "    print(f\"✓ finished {iso_hold}\")\n",
    "\n",
    "# ------------------------------- MAIN ---------------------------------\n",
    "def main() -> None:\n",
    "    BASE_OUT.mkdir(parents=True, exist_ok=True)\n",
    "    df_all = pd.read_csv(CSV_PATH)\n",
    "    iso_list = sorted(df_all[ISO].unique())\n",
    "\n",
    "    print(f\"Found {len(iso_list)} unique isotopes.\")\n",
    "    for iso in iso_list:\n",
    "        process_isotope(df_all, iso)\n",
    "\n",
    "    print(\"\\nAll isotopes done!\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- IMPORTS ----------------------------------\n",
    "import random, pathlib, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------- CONSTANTS --------------------------------\n",
    "CSV_PATH   = \"merged_8_july_d_lowmassremoved.csv\"          # master dataset\n",
    "BASE_OUT   = pathlib.Path(\"results_lam0p6\")   # parent folder for all isotopes\n",
    "DEVICE     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "LAM        = 0.6\n",
    "N_HIDDEN   = 192\n",
    "N_LAYERS   = 2\n",
    "DROPOUT    = 0.0014696708413958846\n",
    "LR         = 0.00046358470164797964\n",
    "\n",
    "MAX_EPOCHS = 200\n",
    "PATIENCE   = 15\n",
    "BATCH_SHUFFLE = True\n",
    "\n",
    "N_RUNS     = 10\n",
    "SEED_BASE  = 1234\n",
    "EPS        = 1e-12\n",
    "\n",
    "FEATURES = [\n",
    "    'ERG','Radius','n_rms_radius','p_rms_radius','octopole_deformation',\n",
    "    'n_chem_erg','Sn','Z','S2p_compound','gamma_deformation','ME',\n",
    "    'BEA_A_daughter','A','Radius_daughter','BEA_A','AM','Radius_compound',\n",
    "    'Pairing_daughter','BEA_compound','beta_deformation','Theory_thresh',\n",
    "    'shell_P','pairing_delta','symmetry_S','excitation_energy',\n",
    "    'Thresh_n3n','Excite_n3n','Thresh_n4n','Excite_n4n'\n",
    "]\n",
    "TARGET, SIGMA_EXP, FLUENCE, GAMMA, ISO = (\n",
    "    \"XS\",\"sigma_exp\",\"fluence\",\"gamma\",\"iso_id\"\n",
    ")\n",
    "\n",
    "# --------------------------- UTILITIES --------------------------------\n",
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# ----------------------- DATASET & SAMPLER ----------------------------\n",
    "class XSData(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, scaler: StandardScaler,\n",
    "                 fit_scaler: bool = False):\n",
    "        if fit_scaler:\n",
    "            scaler.fit(df[FEATURES])\n",
    "        self.X = torch.tensor(scaler.transform(df[FEATURES]).astype(np.float32))\n",
    "        self.y = torch.tensor(df[TARGET].to_numpy(np.float32))\n",
    "        self.fluence   = torch.tensor(df[FLUENCE].to_numpy(np.float32))\n",
    "        self.sigma_exp = torch.tensor(df[SIGMA_EXP].fillna(0).to_numpy(np.float32))\n",
    "        self.gamma     = torch.tensor(df[GAMMA].to_numpy(np.float32))\n",
    "        self.iso_code  = df[ISO].astype(\"category\").cat.codes.to_numpy()\n",
    "\n",
    "    def __len__(self): return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return {\"x\": self.X[idx], \"y\": self.y[idx],\n",
    "                \"fluence\": self.fluence[idx],\n",
    "                \"sigma_exp\": self.sigma_exp[idx],\n",
    "                \"gamma\": self.gamma[idx],\n",
    "                \"iso_code\": self.iso_code[idx]}\n",
    "\n",
    "class IsoBatchSampler(Sampler):\n",
    "    def __init__(self, iso_codes, shuffle=True):\n",
    "        self.indices = {}\n",
    "        for i, iso in enumerate(iso_codes):\n",
    "            self.indices.setdefault(int(iso), []).append(i)\n",
    "        self.keys = list(self.indices.keys())\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        keys = self.keys.copy()\n",
    "        if self.shuffle: random.shuffle(keys)\n",
    "        for k in keys:\n",
    "            yield self.indices[k]\n",
    "\n",
    "    def __len__(self): return len(self.keys)\n",
    "\n",
    "# ------------------------------ MODEL ---------------------------------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in:int, n_hidden:int, n_layers:int, p_drop:float):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for l in range(n_layers):\n",
    "            layers += [nn.Linear(n_in if l==0 else n_hidden, n_hidden),\n",
    "                       nn.ReLU(), nn.Dropout(p_drop)]\n",
    "        layers.append(nn.Linear(n_hidden, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x): return self.net(x).squeeze(1)\n",
    "\n",
    "# -------------------------- CUSTOM LOSS -------------------------------\n",
    "def iso_loss(batch, preds, lam:float):\n",
    "    mse = nn.functional.mse_loss(preds, batch[\"y\"])\n",
    "    if batch[\"gamma\"][0] == 0:     # skip σ₁g term if γ = 0\n",
    "        return mse\n",
    "    flu        = batch[\"fluence\"]\n",
    "    sigma_pred = (flu * preds).sum() / (flu.sum() + EPS)\n",
    "    sigma_true = batch[\"sigma_exp\"][0]\n",
    "    rel_err_sq = ((sigma_pred - sigma_true) / (sigma_true + EPS))**2\n",
    "    return mse + lam * rel_err_sq\n",
    "\n",
    "# ------------------------ TRAIN / VALID LOOP --------------------------\n",
    "def run_epoch(model, loader, opt, lam):\n",
    "    is_train = opt is not None\n",
    "    model.train(is_train)\n",
    "    total, n = 0.0, 0\n",
    "    for batch in loader:\n",
    "        batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                 for k,v in batch.items()}\n",
    "        preds = model(batch[\"x\"])\n",
    "        loss  = iso_loss(batch, preds, lam)\n",
    "        if is_train:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        total += loss.item() * len(preds)\n",
    "        n     += len(preds)\n",
    "    return total / n\n",
    "\n",
    "# ----------------------- PER-ISOTOPE ROUTINE --------------------------\n",
    "def process_isotope(df_all: pd.DataFrame, iso_hold: str) -> None:\n",
    "    out_dir = BASE_OUT / iso_hold\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df_test  = df_all[df_all[ISO] == iso_hold].reset_index(drop=True)\n",
    "    df_train = df_all[df_all[ISO] != iso_hold].reset_index(drop=True)\n",
    "    if df_test.empty:\n",
    "        print(f\"⚠  No rows for iso_id={iso_hold}; skipping.\")\n",
    "        return\n",
    "\n",
    "    preds_runs = []\n",
    "    for run in range(N_RUNS):\n",
    "        set_seed(SEED_BASE + run)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        ds_tr  = XSData(df_train, scaler, fit_scaler=True)\n",
    "        ds_te  = XSData(df_test,  scaler, fit_scaler=False)\n",
    "\n",
    "        dl_tr = DataLoader(ds_tr, batch_sampler=IsoBatchSampler(ds_tr.iso_code,\n",
    "                                                                shuffle=BATCH_SHUFFLE))\n",
    "        dl_te = DataLoader(ds_te, batch_sampler=IsoBatchSampler(ds_te.iso_code,\n",
    "                                                                shuffle=False))\n",
    "\n",
    "        model = MLP(len(FEATURES), N_HIDDEN, N_LAYERS, DROPOUT).to(DEVICE)\n",
    "        opt   = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "        best, patience = float(\"inf\"), 0\n",
    "        for _ in range(MAX_EPOCHS):\n",
    "            loss_tr = run_epoch(model, dl_tr, opt, LAM)\n",
    "            if loss_tr < best - 1e-6:\n",
    "                best, patience = loss_tr, 0\n",
    "            else:\n",
    "                patience += 1\n",
    "                if patience >= PATIENCE:\n",
    "                    break\n",
    "\n",
    "        # predict\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dl_te:\n",
    "                batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                         for k,v in batch.items()}\n",
    "                preds.append(model(batch[\"x\"]).cpu())\n",
    "        preds_runs.append(torch.cat(preds).numpy())\n",
    "\n",
    "    preds_arr  = np.stack(preds_runs, axis=1)\n",
    "    pred_mean  = preds_arr.mean(axis=1)\n",
    "\n",
    "    # save CSV ----------------------------------------------------------\n",
    "    df_out = pd.DataFrame({\"ERG\": df_test[\"ERG\"], \"XS_true\": df_test[\"XS\"]})\n",
    "    for r in range(N_RUNS):\n",
    "        df_out[f\"pred_run{r+1}\"] = preds_arr[:, r]\n",
    "    df_out[\"pred_mean\"] = pred_mean\n",
    "    csv_path = out_dir / f\"{iso_hold}_predictions.csv\"\n",
    "    df_out.to_csv(csv_path, index=False)\n",
    "\n",
    "    # plot --------------------------------------------------------------\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(df_out[\"ERG\"], df_out[\"XS_true\"],  lw=2, label=\"True XS\")\n",
    "    plt.plot(df_out[\"ERG\"], df_out[\"pred_mean\"], lw=2, ls=\"--\",\n",
    "             label=f\"Mean pred ({N_RUNS}×)\")\n",
    "    plt.xlabel(\"ERG\"); plt.ylabel(\"XS\")\n",
    "    plt.title(f\"{iso_hold} – true vs predicted XS\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(out_dir / f\"{iso_hold}_erg_vs_pred.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # meta --------------------------------------------------------------\n",
    "    meta = dict(lam=LAM, n_hidden=N_HIDDEN, n_layers=N_LAYERS,\n",
    "                dropout=DROPOUT, lr=LR, n_runs=N_RUNS,\n",
    "                iso_held_out=iso_hold)\n",
    "    with open(out_dir / \"run_meta.json\", \"w\") as fh:\n",
    "        json.dump(meta, fh, indent=2)\n",
    "\n",
    "    print(f\"✓ finished {iso_hold}\")\n",
    "\n",
    "# ------------------------------- MAIN ---------------------------------\n",
    "def main() -> None:\n",
    "    BASE_OUT.mkdir(parents=True, exist_ok=True)\n",
    "    df_all   = pd.read_csv(CSV_PATH)\n",
    "    iso_list = sorted(df_all[ISO].unique())\n",
    "\n",
    "    print(f\"Found {len(iso_list)} unique isotopes.\")\n",
    "    for iso in iso_list:\n",
    "        process_isotope(df_all, iso)\n",
    "\n",
    "    print(\"\\nAll isotopes done!\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- IMPORTS ----------------------------------\n",
    "import random, pathlib, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------- CONSTANTS --------------------------------\n",
    "CSV_PATH   = \"merged_8_july_d_lowmassremoved.csv\"          # master dataset\n",
    "BASE_OUT   = pathlib.Path(\"results_lam0p7\")   # parent folder for all isotopes\n",
    "DEVICE     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "LAM        = 0.7\n",
    "N_HIDDEN   = 160\n",
    "N_LAYERS   = 2\n",
    "DROPOUT    = 0.011148537065922611\n",
    "LR         = 0.0003653645325246077\n",
    "\n",
    "MAX_EPOCHS = 200\n",
    "PATIENCE   = 15\n",
    "BATCH_SHUFFLE = True\n",
    "\n",
    "N_RUNS     = 10\n",
    "SEED_BASE  = 1234\n",
    "EPS        = 1e-12\n",
    "\n",
    "FEATURES = [\n",
    "    'ERG','Radius','n_rms_radius','p_rms_radius','octopole_deformation',\n",
    "    'n_chem_erg','Sn','Z','S2p_compound','gamma_deformation','ME',\n",
    "    'BEA_A_daughter','A','Radius_daughter','BEA_A','AM','Radius_compound',\n",
    "    'Pairing_daughter','BEA_compound','beta_deformation','Theory_thresh',\n",
    "    'shell_P','pairing_delta','symmetry_S','excitation_energy',\n",
    "    'Thresh_n3n','Excite_n3n','Thresh_n4n','Excite_n4n'\n",
    "]\n",
    "TARGET, SIGMA_EXP, FLUENCE, GAMMA, ISO = (\n",
    "    \"XS\",\"sigma_exp\",\"fluence\",\"gamma\",\"iso_id\"\n",
    ")\n",
    "\n",
    "# --------------------------- UTILITIES --------------------------------\n",
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# ----------------------- DATASET & SAMPLER ----------------------------\n",
    "class XSData(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, scaler: StandardScaler,\n",
    "                 fit_scaler: bool = False):\n",
    "        if fit_scaler:\n",
    "            scaler.fit(df[FEATURES])\n",
    "        self.X = torch.tensor(scaler.transform(df[FEATURES]).astype(np.float32))\n",
    "        self.y = torch.tensor(df[TARGET].to_numpy(np.float32))\n",
    "        self.fluence   = torch.tensor(df[FLUENCE].to_numpy(np.float32))\n",
    "        self.sigma_exp = torch.tensor(df[SIGMA_EXP].fillna(0).to_numpy(np.float32))\n",
    "        self.gamma     = torch.tensor(df[GAMMA].to_numpy(np.float32))\n",
    "        self.iso_code  = df[ISO].astype(\"category\").cat.codes.to_numpy()\n",
    "\n",
    "    def __len__(self): return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return {\"x\": self.X[idx], \"y\": self.y[idx],\n",
    "                \"fluence\": self.fluence[idx],\n",
    "                \"sigma_exp\": self.sigma_exp[idx],\n",
    "                \"gamma\": self.gamma[idx],\n",
    "                \"iso_code\": self.iso_code[idx]}\n",
    "\n",
    "class IsoBatchSampler(Sampler):\n",
    "    def __init__(self, iso_codes, shuffle=True):\n",
    "        self.indices = {}\n",
    "        for i, iso in enumerate(iso_codes):\n",
    "            self.indices.setdefault(int(iso), []).append(i)\n",
    "        self.keys = list(self.indices.keys())\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        keys = self.keys.copy()\n",
    "        if self.shuffle: random.shuffle(keys)\n",
    "        for k in keys:\n",
    "            yield self.indices[k]\n",
    "\n",
    "    def __len__(self): return len(self.keys)\n",
    "\n",
    "# ------------------------------ MODEL ---------------------------------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in:int, n_hidden:int, n_layers:int, p_drop:float):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for l in range(n_layers):\n",
    "            layers += [nn.Linear(n_in if l==0 else n_hidden, n_hidden),\n",
    "                       nn.ReLU(), nn.Dropout(p_drop)]\n",
    "        layers.append(nn.Linear(n_hidden, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x): return self.net(x).squeeze(1)\n",
    "\n",
    "# -------------------------- CUSTOM LOSS -------------------------------\n",
    "def iso_loss(batch, preds, lam:float):\n",
    "    mse = nn.functional.mse_loss(preds, batch[\"y\"])\n",
    "    if batch[\"gamma\"][0] == 0:     # skip σ₁g term if γ = 0\n",
    "        return mse\n",
    "    flu        = batch[\"fluence\"]\n",
    "    sigma_pred = (flu * preds).sum() / (flu.sum() + EPS)\n",
    "    sigma_true = batch[\"sigma_exp\"][0]\n",
    "    rel_err_sq = ((sigma_pred - sigma_true) / (sigma_true + EPS))**2\n",
    "    return mse + lam * rel_err_sq\n",
    "\n",
    "# ------------------------ TRAIN / VALID LOOP --------------------------\n",
    "def run_epoch(model, loader, opt, lam):\n",
    "    is_train = opt is not None\n",
    "    model.train(is_train)\n",
    "    total, n = 0.0, 0\n",
    "    for batch in loader:\n",
    "        batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                 for k,v in batch.items()}\n",
    "        preds = model(batch[\"x\"])\n",
    "        loss  = iso_loss(batch, preds, lam)\n",
    "        if is_train:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        total += loss.item() * len(preds)\n",
    "        n     += len(preds)\n",
    "    return total / n\n",
    "\n",
    "# ----------------------- PER-ISOTOPE ROUTINE --------------------------\n",
    "def process_isotope(df_all: pd.DataFrame, iso_hold: str) -> None:\n",
    "    out_dir = BASE_OUT / iso_hold\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df_test  = df_all[df_all[ISO] == iso_hold].reset_index(drop=True)\n",
    "    df_train = df_all[df_all[ISO] != iso_hold].reset_index(drop=True)\n",
    "    if df_test.empty:\n",
    "        print(f\"⚠  No rows for iso_id={iso_hold}; skipping.\")\n",
    "        return\n",
    "\n",
    "    preds_runs = []\n",
    "    for run in range(N_RUNS):\n",
    "        set_seed(SEED_BASE + run)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        ds_tr  = XSData(df_train, scaler, fit_scaler=True)\n",
    "        ds_te  = XSData(df_test,  scaler, fit_scaler=False)\n",
    "\n",
    "        dl_tr = DataLoader(ds_tr, batch_sampler=IsoBatchSampler(ds_tr.iso_code,\n",
    "                                                                shuffle=BATCH_SHUFFLE))\n",
    "        dl_te = DataLoader(ds_te, batch_sampler=IsoBatchSampler(ds_te.iso_code,\n",
    "                                                                shuffle=False))\n",
    "\n",
    "        model = MLP(len(FEATURES), N_HIDDEN, N_LAYERS, DROPOUT).to(DEVICE)\n",
    "        opt   = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "        best, patience = float(\"inf\"), 0\n",
    "        for _ in range(MAX_EPOCHS):\n",
    "            loss_tr = run_epoch(model, dl_tr, opt, LAM)\n",
    "            if loss_tr < best - 1e-6:\n",
    "                best, patience = loss_tr, 0\n",
    "            else:\n",
    "                patience += 1\n",
    "                if patience >= PATIENCE:\n",
    "                    break\n",
    "\n",
    "        # predict\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dl_te:\n",
    "                batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                         for k,v in batch.items()}\n",
    "                preds.append(model(batch[\"x\"]).cpu())\n",
    "        preds_runs.append(torch.cat(preds).numpy())\n",
    "\n",
    "    preds_arr  = np.stack(preds_runs, axis=1)\n",
    "    pred_mean  = preds_arr.mean(axis=1)\n",
    "\n",
    "    # save CSV ----------------------------------------------------------\n",
    "    df_out = pd.DataFrame({\"ERG\": df_test[\"ERG\"], \"XS_true\": df_test[\"XS\"]})\n",
    "    for r in range(N_RUNS):\n",
    "        df_out[f\"pred_run{r+1}\"] = preds_arr[:, r]\n",
    "    df_out[\"pred_mean\"] = pred_mean\n",
    "    csv_path = out_dir / f\"{iso_hold}_predictions.csv\"\n",
    "    df_out.to_csv(csv_path, index=False)\n",
    "\n",
    "    # plot --------------------------------------------------------------\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(df_out[\"ERG\"], df_out[\"XS_true\"],  lw=2, label=\"True XS\")\n",
    "    plt.plot(df_out[\"ERG\"], df_out[\"pred_mean\"], lw=2, ls=\"--\",\n",
    "             label=f\"Mean pred ({N_RUNS}×)\")\n",
    "    plt.xlabel(\"ERG\"); plt.ylabel(\"XS\")\n",
    "    plt.title(f\"{iso_hold} – true vs predicted XS\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(out_dir / f\"{iso_hold}_erg_vs_pred.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # meta --------------------------------------------------------------\n",
    "    meta = dict(lam=LAM, n_hidden=N_HIDDEN, n_layers=N_LAYERS,\n",
    "                dropout=DROPOUT, lr=LR, n_runs=N_RUNS,\n",
    "                iso_held_out=iso_hold)\n",
    "    with open(out_dir / \"run_meta.json\", \"w\") as fh:\n",
    "        json.dump(meta, fh, indent=2)\n",
    "\n",
    "    print(f\"✓ finished {iso_hold}\")\n",
    "\n",
    "# ------------------------------- MAIN ---------------------------------\n",
    "def main() -> None:\n",
    "    BASE_OUT.mkdir(parents=True, exist_ok=True)\n",
    "    df_all   = pd.read_csv(CSV_PATH)\n",
    "    iso_list = sorted(df_all[ISO].unique())\n",
    "\n",
    "    print(f\"Found {len(iso_list)} unique isotopes.\")\n",
    "    for iso in iso_list:\n",
    "        process_isotope(df_all, iso)\n",
    "\n",
    "    print(\"\\nAll isotopes done!\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- IMPORTS ----------------------------------\n",
    "import random, pathlib, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------- CONSTANTS --------------------------------\n",
    "CSV_PATH   = \"merged_8_july_d_lowmassremoved.csv\"          # master dataset\n",
    "BASE_OUT   = pathlib.Path(\"results_lam0p8\")   # parent folder for all isotopes\n",
    "DEVICE     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "LAM        = 0.8\n",
    "N_HIDDEN   = 192\n",
    "N_LAYERS   = 4\n",
    "DROPOUT    = 0.13593330178635776\n",
    "LR         = 0.0007731610563105644\n",
    "\n",
    "MAX_EPOCHS = 200\n",
    "PATIENCE   = 15\n",
    "BATCH_SHUFFLE = True\n",
    "\n",
    "N_RUNS     = 10\n",
    "SEED_BASE  = 1234\n",
    "EPS        = 1e-12\n",
    "\n",
    "FEATURES = [\n",
    "    'ERG','Radius','n_rms_radius','p_rms_radius','octopole_deformation',\n",
    "    'n_chem_erg','Sn','Z','S2p_compound','gamma_deformation','ME',\n",
    "    'BEA_A_daughter','A','Radius_daughter','BEA_A','AM','Radius_compound',\n",
    "    'Pairing_daughter','BEA_compound','beta_deformation','Theory_thresh',\n",
    "    'shell_P','pairing_delta','symmetry_S','excitation_energy',\n",
    "    'Thresh_n3n','Excite_n3n','Thresh_n4n','Excite_n4n'\n",
    "]\n",
    "TARGET, SIGMA_EXP, FLUENCE, GAMMA, ISO = (\n",
    "    \"XS\",\"sigma_exp\",\"fluence\",\"gamma\",\"iso_id\"\n",
    ")\n",
    "\n",
    "# --------------------------- UTILITIES --------------------------------\n",
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# ----------------------- DATASET & SAMPLER ----------------------------\n",
    "class XSData(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, scaler: StandardScaler,\n",
    "                 fit_scaler: bool = False):\n",
    "        if fit_scaler:\n",
    "            scaler.fit(df[FEATURES])\n",
    "        self.X = torch.tensor(scaler.transform(df[FEATURES]).astype(np.float32))\n",
    "        self.y = torch.tensor(df[TARGET].to_numpy(np.float32))\n",
    "        self.fluence   = torch.tensor(df[FLUENCE].to_numpy(np.float32))\n",
    "        self.sigma_exp = torch.tensor(df[SIGMA_EXP].fillna(0).to_numpy(np.float32))\n",
    "        self.gamma     = torch.tensor(df[GAMMA].to_numpy(np.float32))\n",
    "        self.iso_code  = df[ISO].astype(\"category\").cat.codes.to_numpy()\n",
    "\n",
    "    def __len__(self): return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return {\"x\": self.X[idx], \"y\": self.y[idx],\n",
    "                \"fluence\": self.fluence[idx],\n",
    "                \"sigma_exp\": self.sigma_exp[idx],\n",
    "                \"gamma\": self.gamma[idx],\n",
    "                \"iso_code\": self.iso_code[idx]}\n",
    "\n",
    "class IsoBatchSampler(Sampler):\n",
    "    def __init__(self, iso_codes, shuffle=True):\n",
    "        self.indices = {}\n",
    "        for i, iso in enumerate(iso_codes):\n",
    "            self.indices.setdefault(int(iso), []).append(i)\n",
    "        self.keys = list(self.indices.keys())\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        keys = self.keys.copy()\n",
    "        if self.shuffle: random.shuffle(keys)\n",
    "        for k in keys:\n",
    "            yield self.indices[k]\n",
    "\n",
    "    def __len__(self): return len(self.keys)\n",
    "\n",
    "# ------------------------------ MODEL ---------------------------------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in:int, n_hidden:int, n_layers:int, p_drop:float):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for l in range(n_layers):\n",
    "            layers += [nn.Linear(n_in if l==0 else n_hidden, n_hidden),\n",
    "                       nn.ReLU(), nn.Dropout(p_drop)]\n",
    "        layers.append(nn.Linear(n_hidden, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x): return self.net(x).squeeze(1)\n",
    "\n",
    "# -------------------------- CUSTOM LOSS -------------------------------\n",
    "def iso_loss(batch, preds, lam:float):\n",
    "    mse = nn.functional.mse_loss(preds, batch[\"y\"])\n",
    "    if batch[\"gamma\"][0] == 0:     # skip σ₁g term if γ = 0\n",
    "        return mse\n",
    "    flu        = batch[\"fluence\"]\n",
    "    sigma_pred = (flu * preds).sum() / (flu.sum() + EPS)\n",
    "    sigma_true = batch[\"sigma_exp\"][0]\n",
    "    rel_err_sq = ((sigma_pred - sigma_true) / (sigma_true + EPS))**2\n",
    "    return mse + lam * rel_err_sq\n",
    "\n",
    "# ------------------------ TRAIN / VALID LOOP --------------------------\n",
    "def run_epoch(model, loader, opt, lam):\n",
    "    is_train = opt is not None\n",
    "    model.train(is_train)\n",
    "    total, n = 0.0, 0\n",
    "    for batch in loader:\n",
    "        batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                 for k,v in batch.items()}\n",
    "        preds = model(batch[\"x\"])\n",
    "        loss  = iso_loss(batch, preds, lam)\n",
    "        if is_train:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        total += loss.item() * len(preds)\n",
    "        n     += len(preds)\n",
    "    return total / n\n",
    "\n",
    "# ----------------------- PER-ISOTOPE ROUTINE --------------------------\n",
    "def process_isotope(df_all: pd.DataFrame, iso_hold: str) -> None:\n",
    "    out_dir = BASE_OUT / iso_hold\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df_test  = df_all[df_all[ISO] == iso_hold].reset_index(drop=True)\n",
    "    df_train = df_all[df_all[ISO] != iso_hold].reset_index(drop=True)\n",
    "    if df_test.empty:\n",
    "        print(f\"⚠  No rows for iso_id={iso_hold}; skipping.\")\n",
    "        return\n",
    "\n",
    "    preds_runs = []\n",
    "    for run in range(N_RUNS):\n",
    "        set_seed(SEED_BASE + run)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        ds_tr  = XSData(df_train, scaler, fit_scaler=True)\n",
    "        ds_te  = XSData(df_test,  scaler, fit_scaler=False)\n",
    "\n",
    "        dl_tr = DataLoader(ds_tr, batch_sampler=IsoBatchSampler(ds_tr.iso_code,\n",
    "                                                                shuffle=BATCH_SHUFFLE))\n",
    "        dl_te = DataLoader(ds_te, batch_sampler=IsoBatchSampler(ds_te.iso_code,\n",
    "                                                                shuffle=False))\n",
    "\n",
    "        model = MLP(len(FEATURES), N_HIDDEN, N_LAYERS, DROPOUT).to(DEVICE)\n",
    "        opt   = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "        best, patience = float(\"inf\"), 0\n",
    "        for _ in range(MAX_EPOCHS):\n",
    "            loss_tr = run_epoch(model, dl_tr, opt, LAM)\n",
    "            if loss_tr < best - 1e-6:\n",
    "                best, patience = loss_tr, 0\n",
    "            else:\n",
    "                patience += 1\n",
    "                if patience >= PATIENCE:\n",
    "                    break\n",
    "\n",
    "        # predict\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dl_te:\n",
    "                batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                         for k,v in batch.items()}\n",
    "                preds.append(model(batch[\"x\"]).cpu())\n",
    "        preds_runs.append(torch.cat(preds).numpy())\n",
    "\n",
    "    preds_arr  = np.stack(preds_runs, axis=1)\n",
    "    pred_mean  = preds_arr.mean(axis=1)\n",
    "\n",
    "    # save CSV ----------------------------------------------------------\n",
    "    df_out = pd.DataFrame({\"ERG\": df_test[\"ERG\"], \"XS_true\": df_test[\"XS\"]})\n",
    "    for r in range(N_RUNS):\n",
    "        df_out[f\"pred_run{r+1}\"] = preds_arr[:, r]\n",
    "    df_out[\"pred_mean\"] = pred_mean\n",
    "    csv_path = out_dir / f\"{iso_hold}_predictions.csv\"\n",
    "    df_out.to_csv(csv_path, index=False)\n",
    "\n",
    "    # plot --------------------------------------------------------------\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(df_out[\"ERG\"], df_out[\"XS_true\"],  lw=2, label=\"True XS\")\n",
    "    plt.plot(df_out[\"ERG\"], df_out[\"pred_mean\"], lw=2, ls=\"--\",\n",
    "             label=f\"Mean pred ({N_RUNS}×)\")\n",
    "    plt.xlabel(\"ERG\"); plt.ylabel(\"XS\")\n",
    "    plt.title(f\"{iso_hold} – true vs predicted XS\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(out_dir / f\"{iso_hold}_erg_vs_pred.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # meta --------------------------------------------------------------\n",
    "    meta = dict(lam=LAM, n_hidden=N_HIDDEN, n_layers=N_LAYERS,\n",
    "                dropout=DROPOUT, lr=LR, n_runs=N_RUNS,\n",
    "                iso_held_out=iso_hold)\n",
    "    with open(out_dir / \"run_meta.json\", \"w\") as fh:\n",
    "        json.dump(meta, fh, indent=2)\n",
    "\n",
    "    print(f\"✓ finished {iso_hold}\")\n",
    "\n",
    "# ------------------------------- MAIN ---------------------------------\n",
    "def main() -> None:\n",
    "    BASE_OUT.mkdir(parents=True, exist_ok=True)\n",
    "    df_all   = pd.read_csv(CSV_PATH)\n",
    "    iso_list = sorted(df_all[ISO].unique())\n",
    "\n",
    "    print(f\"Found {len(iso_list)} unique isotopes.\")\n",
    "    for iso in iso_list:\n",
    "        process_isotope(df_all, iso)\n",
    "\n",
    "    print(\"\\nAll isotopes done!\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- IMPORTS ----------------------------------\n",
    "import random, pathlib, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------- CONSTANTS --------------------------------\n",
    "CSV_PATH   = \"merged_8_july_d_lowmassremoved.csv\"          # master dataset\n",
    "BASE_OUT   = pathlib.Path(\"results_lam0p9\")   # parent folder for all isotopes\n",
    "DEVICE     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "LAM        = 0.9\n",
    "N_HIDDEN   = 128\n",
    "N_LAYERS   = 4\n",
    "DROPOUT    = 0.2149288100502335\n",
    "LR         = 0.00022844523281162816\n",
    "\n",
    "MAX_EPOCHS = 200\n",
    "PATIENCE   = 15\n",
    "BATCH_SHUFFLE = True\n",
    "\n",
    "N_RUNS     = 10\n",
    "SEED_BASE  = 1234\n",
    "EPS        = 1e-12\n",
    "\n",
    "FEATURES = [\n",
    "    'ERG','Radius','n_rms_radius','p_rms_radius','octopole_deformation',\n",
    "    'n_chem_erg','Sn','Z','S2p_compound','gamma_deformation','ME',\n",
    "    'BEA_A_daughter','A','Radius_daughter','BEA_A','AM','Radius_compound',\n",
    "    'Pairing_daughter','BEA_compound','beta_deformation','Theory_thresh',\n",
    "    'shell_P','pairing_delta','symmetry_S','excitation_energy',\n",
    "    'Thresh_n3n','Excite_n3n','Thresh_n4n','Excite_n4n'\n",
    "]\n",
    "TARGET, SIGMA_EXP, FLUENCE, GAMMA, ISO = (\n",
    "    \"XS\",\"sigma_exp\",\"fluence\",\"gamma\",\"iso_id\"\n",
    ")\n",
    "\n",
    "# --------------------------- UTILITIES --------------------------------\n",
    "def set_seed(seed: int) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# ----------------------- DATASET & SAMPLER ----------------------------\n",
    "class XSData(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, scaler: StandardScaler,\n",
    "                 fit_scaler: bool = False):\n",
    "        if fit_scaler:\n",
    "            scaler.fit(df[FEATURES])\n",
    "        self.X = torch.tensor(scaler.transform(df[FEATURES]).astype(np.float32))\n",
    "        self.y = torch.tensor(df[TARGET].to_numpy(np.float32))\n",
    "        self.fluence   = torch.tensor(df[FLUENCE].to_numpy(np.float32))\n",
    "        self.sigma_exp = torch.tensor(df[SIGMA_EXP].fillna(0).to_numpy(np.float32))\n",
    "        self.gamma     = torch.tensor(df[GAMMA].to_numpy(np.float32))\n",
    "        self.iso_code  = df[ISO].astype(\"category\").cat.codes.to_numpy()\n",
    "\n",
    "    def __len__(self): return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return {\"x\": self.X[idx], \"y\": self.y[idx],\n",
    "                \"fluence\": self.fluence[idx],\n",
    "                \"sigma_exp\": self.sigma_exp[idx],\n",
    "                \"gamma\": self.gamma[idx],\n",
    "                \"iso_code\": self.iso_code[idx]}\n",
    "\n",
    "class IsoBatchSampler(Sampler):\n",
    "    def __init__(self, iso_codes, shuffle=True):\n",
    "        self.indices = {}\n",
    "        for i, iso in enumerate(iso_codes):\n",
    "            self.indices.setdefault(int(iso), []).append(i)\n",
    "        self.keys = list(self.indices.keys())\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        keys = self.keys.copy()\n",
    "        if self.shuffle: random.shuffle(keys)\n",
    "        for k in keys:\n",
    "            yield self.indices[k]\n",
    "\n",
    "    def __len__(self): return len(self.keys)\n",
    "\n",
    "# ------------------------------ MODEL ---------------------------------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in:int, n_hidden:int, n_layers:int, p_drop:float):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for l in range(n_layers):\n",
    "            layers += [nn.Linear(n_in if l==0 else n_hidden, n_hidden),\n",
    "                       nn.ReLU(), nn.Dropout(p_drop)]\n",
    "        layers.append(nn.Linear(n_hidden, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x): return self.net(x).squeeze(1)\n",
    "\n",
    "# -------------------------- CUSTOM LOSS -------------------------------\n",
    "def iso_loss(batch, preds, lam:float):\n",
    "    mse = nn.functional.mse_loss(preds, batch[\"y\"])\n",
    "    if batch[\"gamma\"][0] == 0:     # skip σ₁g term if γ = 0\n",
    "        return mse\n",
    "    flu        = batch[\"fluence\"]\n",
    "    sigma_pred = (flu * preds).sum() / (flu.sum() + EPS)\n",
    "    sigma_true = batch[\"sigma_exp\"][0]\n",
    "    rel_err_sq = ((sigma_pred - sigma_true) / (sigma_true + EPS))**2\n",
    "    return mse + lam * rel_err_sq\n",
    "\n",
    "# ------------------------ TRAIN / VALID LOOP --------------------------\n",
    "def run_epoch(model, loader, opt, lam):\n",
    "    is_train = opt is not None\n",
    "    model.train(is_train)\n",
    "    total, n = 0.0, 0\n",
    "    for batch in loader:\n",
    "        batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                 for k,v in batch.items()}\n",
    "        preds = model(batch[\"x\"])\n",
    "        loss  = iso_loss(batch, preds, lam)\n",
    "        if is_train:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        total += loss.item() * len(preds)\n",
    "        n     += len(preds)\n",
    "    return total / n\n",
    "\n",
    "# ----------------------- PER-ISOTOPE ROUTINE --------------------------\n",
    "def process_isotope(df_all: pd.DataFrame, iso_hold: str) -> None:\n",
    "    out_dir = BASE_OUT / iso_hold\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df_test  = df_all[df_all[ISO] == iso_hold].reset_index(drop=True)\n",
    "    df_train = df_all[df_all[ISO] != iso_hold].reset_index(drop=True)\n",
    "    if df_test.empty:\n",
    "        print(f\"⚠  No rows for iso_id={iso_hold}; skipping.\")\n",
    "        return\n",
    "\n",
    "    preds_runs = []\n",
    "    for run in range(N_RUNS):\n",
    "        set_seed(SEED_BASE + run)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        ds_tr  = XSData(df_train, scaler, fit_scaler=True)\n",
    "        ds_te  = XSData(df_test,  scaler, fit_scaler=False)\n",
    "\n",
    "        dl_tr = DataLoader(ds_tr, batch_sampler=IsoBatchSampler(ds_tr.iso_code,\n",
    "                                                                shuffle=BATCH_SHUFFLE))\n",
    "        dl_te = DataLoader(ds_te, batch_sampler=IsoBatchSampler(ds_te.iso_code,\n",
    "                                                                shuffle=False))\n",
    "\n",
    "        model = MLP(len(FEATURES), N_HIDDEN, N_LAYERS, DROPOUT).to(DEVICE)\n",
    "        opt   = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "        best, patience = float(\"inf\"), 0\n",
    "        for _ in range(MAX_EPOCHS):\n",
    "            loss_tr = run_epoch(model, dl_tr, opt, LAM)\n",
    "            if loss_tr < best - 1e-6:\n",
    "                best, patience = loss_tr, 0\n",
    "            else:\n",
    "                patience += 1\n",
    "                if patience >= PATIENCE:\n",
    "                    break\n",
    "\n",
    "        # predict\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dl_te:\n",
    "                batch = {k:(v.to(DEVICE) if torch.is_tensor(v) else v)\n",
    "                         for k,v in batch.items()}\n",
    "                preds.append(model(batch[\"x\"]).cpu())\n",
    "        preds_runs.append(torch.cat(preds).numpy())\n",
    "\n",
    "    preds_arr  = np.stack(preds_runs, axis=1)\n",
    "    pred_mean  = preds_arr.mean(axis=1)\n",
    "\n",
    "    # save CSV ----------------------------------------------------------\n",
    "    df_out = pd.DataFrame({\"ERG\": df_test[\"ERG\"], \"XS_true\": df_test[\"XS\"]})\n",
    "    for r in range(N_RUNS):\n",
    "        df_out[f\"pred_run{r+1}\"] = preds_arr[:, r]\n",
    "    df_out[\"pred_mean\"] = pred_mean\n",
    "    csv_path = out_dir / f\"{iso_hold}_predictions.csv\"\n",
    "    df_out.to_csv(csv_path, index=False)\n",
    "\n",
    "    # plot --------------------------------------------------------------\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(df_out[\"ERG\"], df_out[\"XS_true\"],  lw=2, label=\"True XS\")\n",
    "    plt.plot(df_out[\"ERG\"], df_out[\"pred_mean\"], lw=2, ls=\"--\",\n",
    "             label=f\"Mean pred ({N_RUNS}×)\")\n",
    "    plt.xlabel(\"ERG\"); plt.ylabel(\"XS\")\n",
    "    plt.title(f\"{iso_hold} – true vs predicted XS\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(out_dir / f\"{iso_hold}_erg_vs_pred.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # meta --------------------------------------------------------------\n",
    "    meta = dict(lam=LAM, n_hidden=N_HIDDEN, n_layers=N_LAYERS,\n",
    "                dropout=DROPOUT, lr=LR, n_runs=N_RUNS,\n",
    "                iso_held_out=iso_hold)\n",
    "    with open(out_dir / \"run_meta.json\", \"w\") as fh:\n",
    "        json.dump(meta, fh, indent=2)\n",
    "\n",
    "    print(f\"✓ finished {iso_hold}\")\n",
    "\n",
    "# ------------------------------- MAIN ---------------------------------\n",
    "def main() -> None:\n",
    "    BASE_OUT.mkdir(parents=True, exist_ok=True)\n",
    "    df_all   = pd.read_csv(CSV_PATH)\n",
    "    iso_list = sorted(df_all[ISO].unique())\n",
    "\n",
    "    print(f\"Found {len(iso_list)} unique isotopes.\")\n",
    "    for iso in iso_list:\n",
    "        process_isotope(df_all, iso)\n",
    "\n",
    "    print(\"\\nAll isotopes done!\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
